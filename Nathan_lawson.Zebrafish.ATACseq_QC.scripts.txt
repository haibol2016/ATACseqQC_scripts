

           Nathan_Lawson zebrafish ATACseqQC using the reference genome-zv9
           					Author: Haibo Liu
                            Date:   April, 2018



#########################################################################################
										Working directory: 
 /project/umw_nathan_lawson/deep_seq_data/PreProcess/26MAR18_MiSeq_BPJMM

#########################################################################################


#################################  1. Raw reads FASTQC  #################################
#!/bin/bash

#BSUB -n 1 # minmal numbers of processors required for a parallel job
#BSUB -R rusage[mem=64000] # ask for memory 16G
#BSUB -W 12:00 #limit the job to be finished in 12 hours
#BSUB -J "bwamem[1]"
#BSUB -q long # which queue we want to run in
#BSUB -o logs/out.%J.%I.txt # log
#BSUB -e logs/err.%J.%I.txt # error
#BSUB -R "span[hosts=1]" # All hosts on the same chassis"

module load bwa/0.7.15 
mkdir -p logs
i=$(($LSB_JOBINDEX - 1))
out=results/fastqc.out
fastq=(`ls  fastq/*.fastq.gz`)

fastqc  -o $out  ${fastq[$i]}

##################### 1.1 Run MultiQC to generate report  ###############################

#!/bin/bash

#BSUB -n 1 # minmal numbers of processors required for a parallel job
#BSUB -R rusage[mem=64000] # ask for memory 16G
#BSUB -W 12:00 #limit the job to be finished in 12 hours
#BSUB -J "bwamem[1]"
#BSUB -q long # which queue we want to run in
#BSUB -o logs/out.%J.%I.txt # log
#BSUB -e logs/err.%J.%I.txt # error
#BSUB -R "span[hosts=1]" # All hosts on the same chassis"

mkdir -p logs

## using virtual environment
source ~/project/umw_mccb/bin/python2.7.9_virtual_env/bin/activate
multiqc --filename  Nathan.pilot.ATACseq.FASTQC.report  --outdir   results/fastqc.out   results/fastqc.out


deactivate



######################  2. Build genome index using bwa-mem  #############################
#!/bin/bash

#BSUB -n 1 # minmal numbers of processors required for a parallel job
#BSUB -R rusage[mem=64000] # ask for memory 16G
#BSUB -W 12:00 #limit the job to be finished in 12 hours
#BSUB -J "bwamem[1]"
#BSUB -q long # which queue we want to run in
#BSUB -o logs/out.%J.%I.txt # log
#BSUB -e logs/err.%J.%I.txt # error
#BSUB -R "span[hosts=1]" # All hosts on the same chassis"

module load bwa/0.7.15 
mkdir -p logs

fasta=/home/hl24w/project/umw_mccb/genome/Zebrafish/Zv9_NCBI/Danio_rerio.Zv9.dna.toplevel.fa

bwa index  $fasta


##### 3. mapping reads to the zebrafish ref genome Zv9 from the Ensembl gene 79 ###########
#!/bin/bash

#BSUB -n 8 # minmal numbers of processors required for a parallel job
#BSUB -R rusage[mem=16000] # ask for memory 16G
#BSUB -W 72:00 #limit the job to be finished in 12 hours
#BSUB -J "bwamem[1-4]"
#BSUB -q long # which queue we want to run in
#BSUB -o logs/out.%J.%I.txt # log
#BSUB -e logs/err.%J.%I.txt # error
#BSUB -R "span[hosts=1]" # All hosts on the same chassis"
#BSUB -w "done(1894049)"

module load bwa/0.7.15 
module load samtools/1.4.1
mkdir -p logs

out=BWA.out
mkdir -p $out

i=$(($LSB_JOBINDEX - 1))
R1=(`ls WT*_R1_001.fastq.gz`)
R2=(`ls WT*_R2_001.fastq.gz`)
names=(`ls WT*_R2_001.fastq.gz | perl -p -e 's/(WT\d+k).+/$1/' `)
fasta=/home/hl24w/project/umw_mccb/genome/Zebrafish/Zv9_NCBI/Danio_rerio.Zv9.dna.toplevel.fa

bwa mem -t 8 -M  $fasta ${R1[$i]}  ${R2[$i]}  | \
       samtools view -b -h  -o  ${out}/${names[$i]}.bam  -@ 8  -1  -


############################ 4. QC of the alignment BAM file  ############################

#!/bin/bash

## "Zebrafish.nuclear.chr.txt" is a file containing a list of all zebrafish chromosomes 
## and unplaced scaffolds

samtools view -H  WT10k.bam | grep '^@SQ'  |cut -f2 | \
        perl -n -e 's/SN://; print if !/MT/'  > Zebrafish.nuclear.chr.txt

#BSUB -n 8 # minmal numbers of processors required for a parallel job
#BSUB -R rusage[mem=16000] # ask for memory 16G
#BSUB -W 12:00 #limit the job to be finished in 12 hours
#BSUB -J "bwamem[1-4]"
#BSUB -q long # which queue we want to run in
#BSUB -o logs/out.%J.%I.txt # log
#BSUB -e logs/err.%J.%I.txt # error
#BSUB -R "span[hosts=1]" # All hosts on the same chassis"


module load samtools/1.4.1

i=$(($LSB_JOBINDEX - 1))

chromosomes=(`cat nuclear.chr.txt`)

bams=(`ls *[0-9]k.bam `)
names=(`ls *[0-9]k.bam| perl -p -e 's/.bam//' `)


## sorting BAM
samtools sort -l 9 -m 8G  -o  ${names[${i}]}.sorted.bam  -O BAM -@ 8  ${bams[$i]}
samtools index  -@ 1  ${names[${i}]}.sorted.bam

## statistics of read alignments
samtools flagstat -@ 8  ${names[${i}]}.sorted.bam  > ${names[${i}]}.prefilter.stat

## extract mitochondrial reads and summarize their mapping statistics

samtools view  -h  -b   ${names[${i}]}.sorted.bam   'MT' > ${names[${i}]}.MT.bam

samtools flagstat -@ 8  ${names[${i}]}.MT.bam > ${names[${i}]}.MT.bam.stat


## filtering BAM files to remove mitochondrial reads and other alignments of no interest
samtools view  -h -O SAM   ${names[${i}]}.sorted.bam    ${chromosomes[@]} | awk  'BEGIN{FS=OFS="\t"} \
    function abs(v) {return v < 0 ? -v : v}; /^@/ || ($7 == "="  \
    && ($2 == 81 || $2 == 161|| $2 == 97 || $2 == 145 || $2 ==99 || \
    $2 == 147 || $2 == 83 || $2 ==163) && abs($9) <= 2000 && abs($9) >= 38 && $5 >=20 ) {print}' | \
    samtools view  -h  -b -o ${names[${i}]}.chr.filtered.bam  - 


## sort and index BAM files

samtools sort -l 9 -m 8G  -o  ${names[${i}]}.chr.filtered.sorted.bam  -O BAM -@ 8  ${names[${i}]}.chr.filtered.bam
samtools index  -@ 1  ${names[${i}]}.chr.filtered.sorted.bam


## summary statistics of BAM files after filtering

samtools flagstat -@ 8  ${names[${i}]}.chr.filtered.sorted.bam > ${names[${i}]}.chr.filtered.sorted.bam.stat
	
## remove duplicates from filtered BAM files
samtools rmdup  ${names[${i}]}.chr.filtered.sorted.bam  ${names[${i}]}.chr.filtered.sorted.rmdup.bam

## index BAM files
samtools index  -@ 1 ${names[${i}]}.chr.filtered.sorted.rmdup.bam

## summary statistics of BAM files after removing duplicates
samtools flagstat -@ 8  ${names[${i}]}.chr.filtered.sorted.rmdup.bam  > ${names[${i}]}.chr.filtered.sorted.rmdup.bam.stat



############### get reads mapped to each chromosome

#!/bin/bash

#BSUB -n 1 # minmal numbers of processors required for a parallel job
#BSUB -R rusage[mem=8000] # ask for memory 16G
#BSUB -W 4:00 #limit the job to be finished in 12 hours
#BSUB -J "multiQC[1-12]"
#BSUB -q short # which queue we want to run in
#BSUB -o logs/out.%J.%I.txt # log
#BSUB -e logs/err.%J.%I.txt # error
#BSUB -R "span[hosts=1]" # All hosts on the same chassis"

mkdir -p logs
module load samtools/1.4.1

i=$(($LSB_JOBINDEX -1))
bams=(`ls results/BWA.out/*.sorted*bam`)
names=(`ls results/BWA.out/*.sorted*bam  | perl -p -e 's/(.+)/$1.idxstats/'`)
## Retrieve and print stats in the index file
samtools idxstats   ${bam[$i]}  >  ${names[$i]}




#### run MultiQC to generate report (supporting stats, flagstats, idxstats and rmdup)

#!/bin/bash

#BSUB -n 1 # minmal numbers of processors required for a parallel job
#BSUB -R rusage[mem=8000] # ask for memory 16G
#BSUB -W 4:00 #limit the job to be finished in 12 hours
#BSUB -J "multiQC[1]"
#BSUB -q short # which queue we want to run in
#BSUB -o logs/out.%J.%I.txt # log
#BSUB -e logs/err.%J.%I.txt # error
#BSUB -R "span[hosts=1]" # All hosts on the same chassis"

mkdir -p logs

## using virtual environment
source ~/project/umw_mccb/bin/python2.7.9_virtual_env/bin/activate
multiqc --filename  Nathan.pilot.ATACseq.BAMQC.report --fullnames  --force  --outdir   results/BWA.out  results/BWA.out 


################## 4.2. generate bigwig tracks from BAM files #############################

#!/bin/bash

#BSUB -n 1 # minmal numbers of processors required for a parallel job
#BSUB -R rusage[mem=64000] # ask for memory 16G
#BSUB -W 12:00 #limit the job to be finished in 12 hours
#BSUB -J "bamCoverage[1-12]"
#BSUB -q long # which queue we want to run in
#BSUB -o logs/out.%J.%I.txt # log
#BSUB -e logs/err.%J.%I.txt # error
#BSUB -R "span[hosts=1]" # All hosts on the same chassis"

mkdir -p logs
i=$(($LSB_JOBINDEX -1))

bams=(`ls results/BWA.out/*sorted*.bam`)
names=(`ls results/BWA.out/*.sorted*bam  | perl -p -e 's/(.+).bam/$1.coverage.bigwig/'`)


## using virtual environment
source ~/project/umw_mccb/bin/Py2.7.9_virtualEnv/bin/activate

bamCoverage -b ${bams[$i]} --outFileFormat bigwig --binSize 20 -p 8 \
            --normalizeUsing  CPM --extendReads  --minMappingQuality 20 -o ${names[$i]}






##################### OPTIONAL: 5. build a BSgenome for zebrafish #######################
#
#
#  It is only necessary to Build a BSgenome object for zebrafish reference genome Zv9 if
#  use the random forest method to split aligned fragments using the splitGAlignmentsByCut
#  function or plot TF footprints using the function factorFootprints()
#
#
#########################################################################################

##input fasta files for each scaffold
## you need 1 FASTA file per sequence that you want to put in the target package. In
## that case the name of each FASTA file must be of the form <prefix><seqname><suffix> 
## where <seqname> is the name of the sequence in it and <prefix> and <suffix> are a 
## prefix and a suffix (possibly empty) that are the same for all the FASTA files

## the suffix would need to be set to .fa.gz. 


## download per chromosome sequence
for chr in $(seq 1 25) MT
do
    wget ftp://ftp.ensembl.org/pub/release-79/fasta/danio_rerio/dna/Danio_rerio.Zv9.dna.chromosome.${chr}.fa.gz
done

wget ftp://ftp.ensembl.org/pub/release-79/fasta/danio_rerio/dna/Danio_rerio.Zv9.dna.nonchromosomal.fa.gz

mv Danio_rerio.Zv9.dna.nonchromosomal.fa.gz Danio_rerio.Zv9.dna.chromosome.Un.fa.gz


## get the lengths of the sequences in a FASTA file

library(Biostrings)
fasta.seqlengths()

## create the BSgenome data package seed file as follows

Package: BSgenome.Drerio.ENSEMBL.danRer7
Title: Full genome sequences for Danio rerio (Ensembl version Zv9)
Description: Full genome sequences for Danio rerio (zebrafish) as provided by ENSEMBL (danrer7) and stored in Biostrings objects.
Version: 1.0.0
Author: Haibo Liu
Maintainer: Haibo Liu <Haibo.Liu@umassmed.edu>
License: GPL-3
organism: Danio rerio
common_name: Zebrafish
provider: ENSEMBL
provider_version: danRer7
release_date: Jul. 2010
release_name: Zebrafish Genome Sequencing Consortium danRer7.0
source_url: ftp://ftp.ensembl.org/pub/release-79/fasta/danio_rerio/dna/Danio_rerio.Zv9.dna.toplevel.fa.gz
organism_biocview: Danio_rerio
BSgenomeObjname: Drerio
seqnames: paste0("", c(1:25, "MT", "Un"))
circ_seqs: "MT"
seqs_srcdir: /home/hl24w/project/umw_mccb/genome/Zebrafish/Zv9_NCBI/per.chr.fasta/
seqfiles_prefix: Danio_rerio.Zv9.dna.chromosome.
seqfiles_suffix: .fa.gz
ondisk_seq_format: fa.rz


#### Build the BSgenome object

library(BSgenome)
if (dir.exists("BSgenome.Drerio.ENSEMBL.danRer7"))
{
	unlink("BSgenome.Drerio.ENSEMBL.danRer7", recursive = TRUE, force = TRUE)
}
forgeBSgenomeDataPkg("/project/umw_mccb/genome/Zebrafish/Zv9_NCBI/build.BSgenome.seed")


 
## Once forgeBSgenomeDataPkg is done, ignore the warnings (if any), quit R
q(save = "n", status = 0, runLast = TRUE)

## and build the source package (tarball) with
R CMD build BSgenome.Drerio.ENSEMBL.danRer7

## check the source package
R CMD check BSgenome.Drerio.ENSEMBL.danRer7_1.0.0.tar.gz

## install the source package
R CMD INSTALL BSgenome.Drerio.ENSEMBL.danRer7_1.0.0.tar.gz
        




############################ 6. Use ATACseqQC to get diagnostic plots ####################

## generate R code for ATACseqQC diagnostic plots: ATACseqQC_plot.R (see below)

#!/usr/bin/env Rscript

## passing one BAM file for QC analysis. An index file per BAM file must be included in 
## the same directory
## Loading all required packages

library(motifStack)
library(ATACseqQC)
library('GenomicFeatures')
library(ChIPpeakAnno)
library(Rsamtools)
library("rtracklayer")

input_dir <- "results/BWA.out"
output_dir <- "results/ATACseqQC.out"

## Getting the BAM file name and sample ID
args<- commandArgs(trailingOnly=TRUE)

bamfile <- args[1]

bamfile.sample.ID <- gsub(".bam", "", basename(bamfile))

## Create a output directory where all subsequent BAM files will be output
outPath <- file.path(output_dir, paste0(bamfile.sample.ID, ".splited.bam"))
if (!dir.exists(outPath)){
   dir.create(outPath, recursive = TRUE)
}

## Plotting size distribution of fragments (Figure 1G)
pdf(file.path(outPath, paste0(bamfile.sample.ID, ".fragment.size.distribution.pdf")), width =10, height=8) 
fragSize <- fragSizeDist(bamFiles=bamfile, bamFiles.labels=bamfile.sample.ID)
dev.off()


## BAM file tags to be included when read in by the Rsamtools
tags <- c("AS", "NM", "MD")


## Build GRangs for the human genome hg38 excluding unplaced scaffoldsand chrY
fish.genome <- read.delim(file.path(input_dir, "auto.x.chrom.zebrafish.txt"), header=F)

seqlev <- as.character(fish.genome[,1])
gr <- GRanges(as.character(fish.genome[,1]), IRanges(fish.genome[,2], fish.genome[,3]))

## For QC, read alignments from chromosomes 1 and 2 are representatitive enough
#which <- gr[seqnames(gr) %in% c("1", "2", "5", "7")]
which <- gr[seqnames(gr) %in% c("1")]


  
## Reading in paired end read alignment
gal <- readBamFile(bamfile, tag=tags, which=which, asMates=TRUE)

## Shifting the coordinates of 5' ends of the aligned reads in the bam file, +4 for reads mapping
## to the positive strand, -5 for reads mapping to the negative strand
gal1 <- shiftGAlignmentsList(gal)
shiftedBamfile <- file.path(outPath, paste0(bamfile.sample.ID,".shifted.bam"))

## Outputting the shifted BAM file
export(gal1, shiftedBamfile)

## Getting information of known transcripts by building txDB from the Ensembl GFF file 
gtf_dir <- "/home/hl24w/project/umw_mccb/genome/Zebrafish/Zv9_NCBI"
gtf_file <- file.path(gtf_dir, "Danio_rerio.Zv9.79.gtf")
                                    
fish_txDB <- makeTxDbFromGFF(file = gtf_file,
                format="gtf",
               dataSource="ENSEMBL",
               organism="Danio rerio",
               circ_seqs="MT")
saveDb(fish_txDB, file=file.path(gtf_dir, "Zv9.sqlite"))
fish_txDB <- loadDb(file.path(gtf_dir, "Zv9.sqlite"))            

txs <- transcripts(fish_txDB)

## split reads into nucleosome-free, mono-, di- and tri-nucleosome bins based on 
## their fragment sizes. Don't use the random forest algorithm, TOO SLOW!!!

objs <- splitGAlignmentsByCut(gal1, txs=txs)


## output split BAM files
null <- writeListOfGAlignments(objs, outPath)

## Heatmap and coverage curve for nucleosome-free and mono-, di- and tri-nucleosome
## occupied regions

bamfiles <- file.path(outPath,
                      c("NucleosomeFree.bam",
                        "mononucleosome.bam",
                        "dinucleosome.bam",
                        "trinucleosome.bam"))

## Extracting TSSs coordinates
TSS <- promoters(txs, upstream=0, downstream=1)
TSS <- unique(TSS)

## Estimating the library size for normalization
librarySize <- estLibSize(bamfiles)


## Calculating the signals around TSSs.
NTILE <- 101
dws <- ups <- 1010

sigs <- enrichedFragments(bamfiles, TSS=TSS,
                          librarySize=librarySize,
                          seqlev=seqlev,
                          TSS.filter=0.5,
                          n.tile = NTILE,
                          upstream = ups,
                          downstream = dws)
                          
                          
## log2 transformed signals
names(sigs) <- gsub(".bam", "", basename(names(sigs)))
sigs.log2 <- lapply(sigs, function(.ele) log2(.ele+1))

## Plotting heatmap showing signals  for nucleosome-free and oligonucleosome-bound 
## regions around TSSs.  (Figure 1 H and 1I)
pdf(file.path(outPath, paste0(bamfile.sample.ID, ".heatmap and averaged coverage.pdf")))
featureAlignedHeatmap(sigs.log2, reCenterPeaks(TSS, width=ups+dws),
                      zeroAt=.5, n.tile=NTILE)

out <- featureAlignedDistribution(sigs, 
                                  reCenterPeaks(TSS, width=ups+dws),
                                  zeroAt=.5, n.tile=NTILE, type="l", 
                                  ylab="Averaged coverage")
dev.off()



### Run ATACseqQC with filtered duplicate removed bam files

#!/bin/bash

#BSUB -n 1 # minmal numbers of processors required for a parallel job
#BSUB -R rusage[mem=32000] # ask for memory 32G
#BSUB -W 72:00 #limit the job to be finished in 72 hours
#BSUB -J "ATACseqQC[1-4]"
#BSUB -q long # which queue we want to run in
#BSUB -o logs/out.%J.%I.txt # log
#BSUB -e logs/err.%J.%I.txt # error
#BSUB -R "span[hosts=1]" # All hosts on the same chassis"

mkdir -p logs
module load R/3.4.0
bams=(`ls results/BWA.out/*.chr.filtered.sorted.rmdup.bam`)
i=$(($LSB_JOBINDEX -1))

chmod +x ATACseqQC_plot.R

./ATACseqQC_plot.R  ${bams[${i}]}








